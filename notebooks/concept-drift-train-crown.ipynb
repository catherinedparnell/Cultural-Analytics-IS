{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os, sys, gzip, csv\n",
    "from glob import glob\n",
    "\n",
    "# core nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# gensim magic\n",
    "import gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cosine similarity \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: eebo-henry_VIII\n",
      "starting: eebo-henry_VII\n",
      "starting: eebo-edward_VI\n",
      "starting: eebo-mary_I\n",
      "starting: eebo-elizabeth_I\n",
      "starting: eebo-james_I\n",
      "starting: eebo-charles_I\n",
      "starting: eebo-oliver_cromwell\n",
      "starting: eebo-charles_II\n"
     ]
    }
   ],
   "source": [
    "# load saved models in order\n",
    "eebo_models = list()\n",
    "input_data = [\n",
    "    \"../models/eebo-henry_VIII.w2v\",\n",
    "    \"../models/eebo-henry_VII.w2v\",\n",
    "    \"../models/eebo-edward_VI.w2v\",\n",
    "    \"../models/eebo-mary_I.w2v\",\n",
    "    \"../models/eebo-elizabeth_I.w2v\",\n",
    "    \"../models/eebo-james_I.w2v\",\n",
    "    \"../models/eebo-charles_I.w2v\",\n",
    "    \"../models/eebo-oliver_cromwell.w2v\",\n",
    "    \"../models/eebo-charles_II.w2v\"\n",
    "]    \n",
    "\n",
    "for fp in input_data:\n",
    "    \n",
    "    model_name = os.path.basename(fp).split(\".\")[0]\n",
    "    print(\"starting: {0}\".format(model_name))\n",
    "    eebo_models.append([model_name,KeyedVectors.load(fp,mmap='r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change_all(model_a, model_b):\n",
    "\n",
    "    # extract all common vocab\n",
    "    common_vocab = [word for word in model_a.vocab if word in model_b.vocab]\n",
    "    common_vectors_a = model_a[common_vocab]\n",
    "    common_vectors_b = model_b[common_vocab]\n",
    "    \n",
    "    # now use Sklearn's LinearRegression to combine vector space\n",
    "    lin_model = LinearRegression()\n",
    "    lin_model.fit(common_vectors_a, common_vectors_b)\n",
    "    \n",
    "    shared_vectors = collections.OrderedDict()\n",
    "    \n",
    "    for word in model_a.vocab:\n",
    "        word_vector = lin_model.predict(model_a[word].reshape(1, -1))\n",
    "        shared_vectors[word] = word_vector.reshape(-1)\n",
    "    \n",
    "    # now add words only in model b\n",
    "    #for word in [word for word in model_b.vocab if word not in common_vocab]:\n",
    "    #    shared_vectors[word] = model_b[word]\n",
    "        \n",
    "    vocab = list(shared_vectors.keys())\n",
    "    shared_embeddings = np.array(list(shared_vectors.values()))\n",
    "    \n",
    "    distances = list()\n",
    "    for word in vocab:\n",
    "        idx = vocab.index(word)\n",
    "        distances.append([word,\n",
    "                          float(cosine_similarity(model_a[word].reshape(1,-1),\n",
    "                                            shared_embeddings[idx].reshape(1,-1)))])    \n",
    "    return(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(data,model):\n",
    "    csvfile = gzip.open('../models/' + str(model) + '-drift.csv.gz', 'wt')\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    for w, d in data:\n",
    "        writer.writerow([w,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eebo-henry_VII', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe253261fd0>]\n",
      "['eebo-edward_VI', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe253261f90>]\n",
      "['eebo-mary_I', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe24b3e4750>]\n",
      "['eebo-elizabeth_I', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe24179f710>]\n",
      "['eebo-james_I', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe20f485ed0>]\n",
      "['eebo-charles_I', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe247ab4050>]\n",
      "['eebo-oliver_cromwell', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe24b4a21d0>]\n",
      "['eebo-charles_II', <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7fe20f485e90>]\n"
     ]
    }
   ],
   "source": [
    "# iterate through models\n",
    "for i, model in enumerate(eebo_models):\n",
    "    if i >= 1:\n",
    "        print(eebo_models[i])\n",
    "        #data = get_change_all(eebo_models[i -1][1], eebo_models[i][1])\n",
    "        #write_csv(data,eebo_models[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
