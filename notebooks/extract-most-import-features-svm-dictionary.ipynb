{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom dictionary\n",
    "custom_dictionary = dict()\n",
    "row_count = 0\n",
    "with open('../lexicons/custom_dictionary.csv', 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "            custom_dictionary[row[0]] = row[1]   \n",
    "            row_count += 1\n",
    "print(\"read\",row_count,\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellProcessor(word):\n",
    "    word = word.lower()\n",
    "    word = word.replace(\"gyftis\", \"gifts\")\n",
    "    word = word.replace(\"gether\", \"gather\")\n",
    "    word = word.replace(\"spirituall\", \"spiritual\")\n",
    "    word = word.replace(\"feythfull\", \"faith\")\n",
    "    word = word.replace(\"wytnes\", \"witness\")\n",
    "    word = word.replace(\"almes\", \"alms\")\n",
    "    word = word.replace(\"desyre\", \"desire\")\n",
    "    word = word.replace(\"selfe\", \"self\")\n",
    "    word = word.replace(\"saffely\", \"safely\")\n",
    "    word = word.replace(\"realme\", \"realm\")\n",
    "    word = word.replace(\"acte\", \"act\")\n",
    "    word = word.replace(\"fourme\", \"form\")\n",
    "    word = word.replace(\"subiectes\", \"subjects\")\n",
    "    word = word.replace(\"theyr\", \"their\")\n",
    "    word = word.replace(\"kynde\", \"kind\")\n",
    "    word = word.replace(\"kynge\", \"king\")\n",
    "    word = word.replace(\"kyndes\", \"kinds\")\n",
    "    word = word.replace(\"vpon\", \"unto\")\n",
    "    word = word.replace(\"purueyours\", \"purveyors\")\n",
    "    word = word.replace(\"highnes\", \"highness\")\n",
    "    word = word.replace(\"euery\", \"every\")\n",
    "    word = word.replace(\"quene\", \"queen\")\n",
    "    word = word.replace(\"quenes\", \"queens\")\n",
    "    word = word.replace(\"whiche\", \"which\")\n",
    "    word = word.replace(\"bloude\", \"blood\")\n",
    "    word = word.replace(\"soueraine\", \"sovereign\")\n",
    "    word = word.replace(\"enactd\", \"enacted\")\n",
    "    word = word.replace(\"vs\", \"us\")\n",
    "    \n",
    "    # replace digits\n",
    "    tmp = list()\n",
    "    for w in word.split():\n",
    "        w = re.sub('\\d','', w)\n",
    "        tmp.append(w)\n",
    "    word = ' '.join(tmp)\n",
    "\n",
    "    #process custom dictionary entries\n",
    "    tmp = list()\n",
    "    for w in word.split():\n",
    "        if w in custom_dictionary:\n",
    "            w = custom_dictionary[w]\n",
    "        tmp.append(w)\n",
    "    word = ' '.join(tmp)\n",
    "    \n",
    "    return word\n",
    "\n",
    "stopWords = [\",\",\"the\",\"and\",\"of\",\"or\",\"to\",\"in\",\"shall\",\"be\",\"that\",\"any\",\"by\",\".\",\n",
    "              \"such\",\"as\",\"this\",\"for\",\"same\",\"all\",\"said\",\"other\",\"'s\",\";\",\n",
    "              \"her\",\"is\",\"every\",\"[\",\"]\",\"they\",\"within\", \"our\", \"not\", \"so\",\n",
    "              \"made\", \"no\", \"then\", \":\", \"do\", \"from\", \"if\", \"it\", \"which\", \"at\", \"with\",\n",
    "             \"thereof\",\"upon\", \"a\", \"because\", \"used\", \"some\", \"but\", \"aforesaid\", \"also\",\n",
    "             \")\",\"(\", \"what\", \"&\", \"may\", \"are\", \"their\", \"them\", \"sayde\", \"suche\", \"shalbe\", \"anye\", \"sayd\",\n",
    "             \"thesaid\", \"/\", \"...\", \"/\", \"either\", \"haue\", \"vnto\", \"thy\", \"did\", \"was\", \"were\", \"have\", \"thee\", \n",
    "             \"your\", \"thou\", \"unto\", \"hath\", \"had\", \"went\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = list()\n",
    "row_count = 0\n",
    "\n",
    "metadata=list()\n",
    "with open('../texts/textMetadata.csv', 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        # deal with the header\n",
    "        if row_count != 0:\n",
    "            metadata.append(row)   \n",
    "        row_count += 1\n",
    "print(\"read\",row_count,\"lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i[4] for i in metadata]\n",
    "files = list()\n",
    "for i in metadata:\n",
    "    fn = \"../texts/\" + i[0]\n",
    "    files.append(fn)\n",
    "    \n",
    "vectorizer = CountVectorizer(\n",
    "    input='filename',\n",
    "    lowercase=True,\n",
    "    ngram_range=(1,3),\n",
    "    strip_accents=None, preprocessor=spellProcessor, stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document term matrix\n",
    "dtm = vectorizer.fit_transform(files)\n",
    "\n",
    "# convert to tf-idf frequencies (to account for differences in text lengths)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "dtm_tfidf = tfidf_transformer.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary counts\n",
    "# (45, 979638) with custom dictionary\n",
    "# (45, 990188) without custom dictionary\n",
    "\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to deal with imbalanced dataset\n",
    "\n",
    "for c in set(labels):\n",
    "    print(\"Class: {0}, Documents: {1}\".format(c,labels.count(c)))\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     np.unique(labels),\n",
    "                                     labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit model using Support Vector Machine (SVM)\n",
    "clf = SGDClassifier(tol=None,class_weight=\"balanced\",max_iter=1000).fit(dtm_tfidf, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will return total count of a term in the vocabulary\n",
    "def get_counts(term):\n",
    "    widx = vectorizer.vocabulary_[term]\n",
    "    return(vocab_sums[0,widx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are our top terms?\n",
    "vocab_sums = dtm.sum(axis=0)\n",
    "sorted_vocab = [(v, vocab_sums[0, i]) for v, i in vectorizer.vocabulary_.items()]\n",
    "sorted_vocab = sorted(sorted_vocab, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# display top twenty words\n",
    "for i in range(1,20):\n",
    "    print(sorted_vocab[i][0],\"->\",sorted_vocab[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce key features for each class\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_list=dict()\n",
    "\n",
    "for cn, cl in enumerate(clf.classes_):\n",
    "    terms = np.argsort(clf.coef_[cn])\n",
    "    values = clf.coef_[cn].ravel()[np.argsort(clf.coef_[cn].ravel())]\n",
    "    print(\"Key features for {}:\".format(cl))\n",
    "    feature_list[cl] = list()\n",
    "    for i, t in enumerate(terms):\n",
    "        # reverse sign\n",
    "        v = -np.round(values[i],3)\n",
    "        feature_list[cl].append((feature_names[t],v))\n",
    "        if i < 50:\n",
    "            print(\"{0} ({1})\".format(feature_names[t],v),end=\", \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data\n",
    "word_cloud_data=dict()\n",
    "for cl in feature_list.keys():\n",
    "    viz_words = feature_list[cl][:25] + feature_list[cl][-25:]\n",
    "    word_cloud_data[cl] = dict()\n",
    "    for i in feature_list[cl][:100]:\n",
    "        word_cloud_data[cl][i[0]] = float(i[1])\n",
    "        \n",
    "    values = [x[1] for x in viz_words]\n",
    "    kwords = [x[0] for x in viz_words]\n",
    "    y_pos = range(len(values))\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    fig = plt.figure(figsize=(35, 20), dpi=75)\n",
    "    plt.barh(y_pos, values, align='center',tick_label=kwords,color=\"red\")\n",
    "    plt.title(\"Key Features: {0}\".format(cl))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# show most important features for each class:\n",
    "for cl in word_cloud_data.keys():\n",
    "    print(\"Class: {0}\".format(cl))\n",
    "    fig = plt.figure(figsize=(35, 20), dpi=75)\n",
    "    wordcloud = WordCloud(width=900,height=500, max_words=1000,\n",
    "                      relative_scaling=1).generate_from_frequencies(word_cloud_data[cl])\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
